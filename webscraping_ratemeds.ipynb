{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initial Code to extract the links and review counts of all the doctors in ratemd\n",
    "import requests,re\n",
    "import pandas\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "l=[]\n",
    "specialities=[]\n",
    "base_url=\"https://www.ratemds.com/il/chicago/\"\n",
    "burl=requests.get(base_url)\n",
    "cont=burl.content\n",
    "basesoup=BeautifulSoup(cont,\"html.parser\")\n",
    "for ul in basesoup.findAll('ul', class_='nav home-specialties-nav hidden-xs'):\n",
    "    for link in ul.findAll(\"li\"):\n",
    "        try:\n",
    "            ngattr= link.attrs[\"ng-class\"]\n",
    "            spec = ngattr.split(\"==\")[1].replace('}','').replace(\"'\",\"\")\n",
    "        except:\n",
    "            spec=None\n",
    "        specialities.append(spec)\n",
    "        \n",
    "specialities.remove(None)\n",
    "#Creating a list of number of pages in each speciality\n",
    "pages = [144,79,192,50,334,17,19,125,79,57,74,15,144]\n",
    "base_url_start=\"https://www.ratemds.com/best-doctors/il/chicago/\"\n",
    "base_url_end=\"/?page=\"\n",
    "for speciality,page in zip(specialities, pages):\n",
    "    for p in range(1, page+1, 1):\n",
    "        print(base_url_start + speciality + base_url_end + str(p))\n",
    "        r=requests.get(base_url_start + speciality + base_url_end + str(p))\n",
    "        c=r.content\n",
    "        #c=r.json()[\"list\"]\n",
    "        soup=BeautifulSoup(c,\"html.parser\")\n",
    "        all=soup.find_all(\"div\",{\"class\":\"search-item doctor-profile\"})\n",
    "        for item in all:\n",
    "            d={}\n",
    "            try:\n",
    "                d[\"Name\"]=item.find(\"a\",{\"class\":\"search-item-doctor-link\"}).text.replace(\"\\n\",\"\")\n",
    "            except:\n",
    "                d[\"Name\"]=None\n",
    "            try:\n",
    "                d[\"Link\"]= \"ratemds.com\" + item.find(\"a\",{\"class\":\"search-item-doctor-link\"}).attrs[\"href\"]\n",
    "            except:\n",
    "                d[\"Link\"]=None\n",
    "            try:\n",
    "                d[\"Speciality\"]=item.find(\"div\",{\"class\":\"search-item-specialty\"}).text.replace(\"\\n\",\"\")\n",
    "            except:\n",
    "                d[\"Speciality\"]=None\n",
    "            try:\n",
    "                d[\"Rating\"]=item.find(\"span\",{\"class\":\"star-rating\"}).attrs[\"title\"]\n",
    "            except:\n",
    "                d[\"Rating\"]=None\n",
    "            try:\n",
    "                d[\"Reviews Count\"]=item.find(\"div\",{\"class\":\"star-rating-count\"}).text.split()[0]\n",
    "            except:\n",
    "                d[\"Reviews Count\"]=None\n",
    "            try:\n",
    "                d[\"Comment\"]=item.find(\"p\",{\"class\":\"rating-comment\"}).text\n",
    "\n",
    "            except:\n",
    "                d[\"Comment\"]=None\n",
    "            l.append(d)\n",
    "\n",
    "df=pandas.DataFrame(l)\n",
    "df\n",
    "df.to_csv(\"ratemd_all_specialities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Final code to extract list of all reviews in each doctor's page\n",
    "import requests,re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "staff_value = []\n",
    "punctuality_value = []\n",
    "helpfulness_value = []\n",
    "knowledge_value = []\n",
    "star_rating = []\n",
    "l = []\n",
    "links = []\n",
    "name = []\n",
    "spec = []\n",
    "star_rating = []\n",
    "comment = []\n",
    "rating_usefulness = []\n",
    "review_date = []\n",
    "\n",
    "#you can either read from the csv created from the previous step or use the df directly\n",
    "#df = pd.read_csv(r'ratemd_all_specialities.csv', encoding='utf8')\n",
    "\n",
    "rows, col = df.shape\n",
    "\n",
    "base_url_start = str(\"https://www.\")\n",
    "\n",
    "#Looping each doctor's link in df\n",
    "for i in range(rows):\n",
    "    k = i+1\n",
    "    print('Doctor '+ str(k) +' is getting scraped')\n",
    "    base_url = str(df.iloc[i]['Link'])\n",
    "    base_url1 = str(\"?page=\")\n",
    "    \n",
    "    reviews = df.iloc[i]['Reviews Count']\n",
    "#Extracting the number of pages for each doctor based on the number of reviews\n",
    "    page_no = math.ceil(reviews/10)\n",
    "\n",
    "    page_no += 1\n",
    "#Looping over each page of each doctor in the outer loop    \n",
    "    for j in range(1, page_no):\n",
    "        base_url2 = str(j)\n",
    "        doc_url = base_url_start + base_url + base_url1 + base_url2\n",
    "\n",
    "        durl=requests.get(doc_url)\n",
    "        dcont=durl.content\n",
    "        docsoup=BeautifulSoup(dcont,\"html.parser\")\n",
    "\n",
    "        alldoc = docsoup.find_all(\"div\", class_=\"col-sm-7\".split())\n",
    "#Looping over all the div elements of class \"col-sm-7\" in that particular page        \n",
    "        for el in alldoc:\n",
    "            all_rating=el.get_text()\n",
    "            links.append(doc_url)\n",
    "            name.append(df.iloc[i]['Name'])\n",
    "            spec.append(df.iloc[i]['Speciality'])\n",
    "            try:\n",
    "                staff_value.append(int(all_rating.split()[0][0]))\n",
    "            except ValueError:\n",
    "                staff_value.append(int(0))\n",
    "            try:\n",
    "                punctuality_value.append(int(all_rating.split()[1][0]))\n",
    "            except ValueError:\n",
    "                punctuality_value.append(int(0))\n",
    "            try:\n",
    "                helpfulness_value.append(int(all_rating.split()[2][0]))\n",
    "            except ValueError:\n",
    "                helpfulness_value.append(int(0))\n",
    "            try:\n",
    "                knowledge_value.append(int(all_rating.split()[3][0]))\n",
    "            except ValueError:           \n",
    "                knowledge_value.append(int(0))\n",
    "#Looping over all the div elements of class \"rating\" in that particular page \n",
    "        all_star_rating=docsoup.find_all(\"div\",{\"class\":\"rating\"})\n",
    "        for item in all_star_rating:\n",
    "            try:\n",
    "                star_rating.append(item.find(\"span\",{\"class\":\"star-rating\"}).attrs[\"title\"])\n",
    "            except:\n",
    "                star_rating.append(0)\n",
    "            try:\n",
    "                comment.append(item.find(\"p\",{\"itemprop\":\"reviewBody\"}).text)\n",
    "            except:\n",
    "                comment.append('NA')\n",
    "            try:\n",
    "                rating_usefulness.append(item.find(\"p\",{\"class\":\"rating-comment-votes pull-left\"}).text.split()[4:])\n",
    "            except:\n",
    "                rating_usefulness.append(0)\n",
    "            try:\n",
    "                review_date.append(item.find(\"p\",{\"class\":\"rating-comment-created pull-right\"}).text.split()[3:])\n",
    "            except:\n",
    "                review_date.append('NA')\n",
    "        print(len(name), len(spec), len(star_rating), len(staff_value), len(punctuality_value), len(helpfulness_value),len(knowledge_value), len(comment), len(review_date), len(links))\n",
    "\n",
    "d ={'Name': name, 'Speciality' : spec, 'Star Rating': star_rating, 'Staff': staff_value, 'Punctuality': punctuality_value, 'Helpfulness': helpfulness_value,'Knowledge': knowledge_value, 'comment': comment,'Rating Usefulness' : rating_usefulness, 'Review Date': review_date,'Link': links}\n",
    "df_links = pd.DataFrame(d)\n",
    "df_links.to_csv(r'Physician_review_dataset.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "df['Rating Usefulness']=df['Rating Usefulness'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\",\"\")) \n",
    "df['Rating Usefulness'] = df['Rating Usefulness'].astype(int)\n",
    "df['Review Date']=df['Review Date'].apply(lambda x: x.replace(\"'\",\"\").replace(\",\",\"\")) \n",
    "df['Review Date'] =pd.to_datetime(df['Review Date'] )\n",
    "df.to_csv('Cleaned_Physician_review_Dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
